# -*- coding: utf-8 -*-
"""Alfonso-Nanquil.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ODw8umA0GCCTq8QtrEWt9FZAMCHbN4Qy

Names: Alfonso, Jay<br>
       Nanquil, Nealian Beth<br>
Course Code & Section: CPE 019 - CPE 32S3<br>
Instructor: Engr. Roman Richard<br>
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install split_folders -q

# Final model

import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from keras.preprocessing.image import ImageDataGenerator
import splitfolders
import tensorflow as tf
from tensorflow.keras import models, layers

Image_size= 256
Batch_size= 32
Channel = 3

data_dir = "/content/drive/MyDrive/Colab Notebooks/Shoe Classification/train"

#To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`

splitfolders.ratio(data_dir,
                   output="./Validation",
                   seed=1337,
                   ratio=(.8, .2),
                   group_prefix=None,
                   move=False) # default values

train_generator = ImageDataGenerator(
        rescale=1./255
).flow_from_directory(
        './Validation/train',
        target_size=(Image_size,Image_size),
        batch_size=Batch_size,
        class_mode="sparse",
)

val_generator = ImageDataGenerator(
        rescale=1./255
).flow_from_directory(
        './Validation/val',
        target_size=(Image_size,Image_size),
        batch_size=Batch_size,
        class_mode="sparse",
)

class_names = list(train_generator.class_indices.keys())
class_names

input_shape=(Image_size,Image_size,Channel)
input_shape



def create_model(input_shape):
    model = models.Sequential([
        layers.InputLayer(input_shape=input_shape),
        layers.Conv2D(32, kernel_size=(3,3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, kernel_size=(3,3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, kernel_size=(3,3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, kernel_size=(3,3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, kernel_size=(3,3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, kernel_size=(3,3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Flatten(),
        layers.Dense(64, activation='relu'),
        layers.Dense(3, activation='sigmoid'),
    ])
    model.compile(optimizer='adam',
                  loss="sparse_categorical_crossentropy",
                  metrics=['accuracy'])
    return model

# start of a test harness

def train_model(model, train_generator, val_generator, batch_size, epochs):
    history = model.fit(
        train_generator,
        validation_data=val_generator,
        batch_size=batch_size,
        epochs=epochs,
        verbose=1
    )
    return history

def evaluate_model(model, val_generator):
    scores = model.evaluate(val_generator, verbose=1)
    print("Test loss:", scores[0])
    print("Test accuracy:", scores[1])
    return scores
epochs = 20
model = create_model(input_shape)
history = train_model(model, train_generator, val_generator, Batch_size, epochs)
scores = evaluate_model(model, val_generator)

# Save the Finalized Model
model.save('/content/drive/MyDrive/Colab Notebooks/Final model h5 format/final_model.h5')

